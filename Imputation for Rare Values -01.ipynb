{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with rare categories in categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In a categorical variable often we see some categories appear a lot more frequent whereas there will be some categories which appear only in few observations.\n",
    "- Categories that appear in a tiny proportion of the observations are rare categories (typically less than 5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level strategy\n",
    "- Merge all categories less than 5% into most dominant category\n",
    "- Group all categories less than 5% into a new category 'Rare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./data/house_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 0:-1], df.SalePrice, test_size=0.3, random_state=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 80)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no. unique values of Street\n",
    "X_train['Street'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pave', 'Grvl'], dtype=object)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values of Street\n",
    "X_train['Street'].unique()\n",
    "\n",
    "# Type of street access to property\n",
    "# Grvl: Gravel\n",
    "# Pave: Paved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_category_percentage(data, col):\n",
    "    print((data[col].value_counts(normalize=True)).apply(lambda x : str(np.round(x * 100, 1)) + '%'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pave    99.5%\n",
      "Grvl     0.5%\n",
      "Name: Street, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# categories of Street\n",
    "display_category_percentage(data = X_train, col = 'Street')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The majority of the houses are located on \"Paved\" streets. \n",
    "- In situations like this, we say that one category is dominating the variable. \n",
    "- Almost the totality of the observations show the same label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different categorical variable scenarios\n",
    "Categorical variables may present themselves in a wide variety of different scenarios. Among these, we find variables with:\n",
    "- One dominating category (most of the observations share the same label)\n",
    "- A few categories\n",
    "- High cardinality (a lot of different categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables with less categories i.e. low cardinality but with one dominant category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def get_small_category_percent(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].dtypes == 'O': # column is Object type\n",
    "            if len(data[col].unique()) < 3: # categorical variable has less than 3 categories\n",
    "                display_category_percentage(data, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pave    99.5%\n",
      "Grvl     0.5%\n",
      "Name: Street, dtype: object\n",
      "\n",
      "AllPub    99.9%\n",
      "NoSeWa     0.1%\n",
      "Name: Utilities, dtype: object\n",
      "\n",
      "Y    93.2%\n",
      "N     6.8%\n",
      "Name: CentralAir, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_small_category_percent(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the first 2 variables, Street and Utilities, the variables show one dominating category which accounts for more than 99% of the observations. \n",
    "* In the third variable, the dominating category is present about 93% of the observations.\n",
    "\n",
    "* In cases of variables with one dominating category, engineering the rare label is not an option. One needs to choose between whether to use that variable as it is at all or remove it from the dataset.\n",
    "* These types of variables often are not useful for our predictions, and we should remove them from the set of features that we are going to use to build machine learning models. \n",
    "* There are of course exceptions, for example in those cases in which the target is unbalanced, and therefore, the presence of the rare label is indeed informative. \n",
    "* The rare label can also be informative in scenarios where the target is not unbalanced.\n",
    "\n",
    "* Therefore, instead of automating a feature engineering pipeline, perhaps it is better to evaluate these variables individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables with few categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None       59.9%\n",
      "BrkFace    29.6%\n",
      "Stone       9.5%\n",
      "BrkCmn      1.0%\n",
      "Name: MasVnrType, dtype: object\n",
      "\n",
      "TA    62.6%\n",
      "Gd    33.3%\n",
      "Ex     2.9%\n",
      "Fa     1.2%\n",
      "Name: ExterQual, dtype: object\n",
      "\n",
      "TA    91.9%\n",
      "Gd     4.6%\n",
      "Fa     3.3%\n",
      "Po     0.2%\n",
      "Name: BsmtCond, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MasVnrType: Masonry veneer type\n",
    "# ExterQual: Evaluates the quality of the material on the exterior\n",
    "# BsmtCond: Evaluates the general condition of the basement\n",
    "\n",
    "cols = ['MasVnrType', 'ExterQual', 'BsmtCond']\n",
    "\n",
    "for col in cols:\n",
    "    display_category_percentage(X_train, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The variables above have only 4 categories. And in all three cases, there is at least one category that is infrequent, this is, that is present in less than 5% of the observations.\n",
    "- When the variable has only a few categories, then perhaps it makes no sense to re-categorise the rare labels into something else. \n",
    "- Lets look for example at the first variable MasVnrType. This variable shows only 1 rare label, BrkCmn. \n",
    "  Thus, re-categorising it into a new label is not an option, because it will leave the variable in the same situation. \n",
    "Replacing of that label by the most frequent category may be done, but ideally, we should first evaluate the distribution of values (for example house prices), within the rare and frequent label. If they are similar, then it makes sense to merge the categories. If the distributions are different however, I would choose to leave the rare label as such and use the original variable without modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MasVnrType     5\n",
       "ExterQual      0\n",
       "BsmtCond      24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check if there are missing data\n",
    "\n",
    "X_train[cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_na(train, test, variable):\n",
    "    most_freq_cat = train.groupby(variable)[variable].count().sort_values(ascending=False).index[0]\n",
    "    train.fillna(most_freq_cat, inplace=True)\n",
    "    test.fillna(most_freq_cat, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['MasVnrType', 'BsmtCond']:\n",
    "    impute_na(X_train, X_test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MasVnrType    0\n",
       "ExterQual     0\n",
       "BsmtCond      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check if there are missing data\n",
    "\n",
    "X_train[cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None       60.1%\n",
      "BrkFace    29.5%\n",
      "Stone       9.5%\n",
      "BrkCmn      1.0%\n",
      "Name: MasVnrType, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['MasVnrType']\n",
    "\n",
    "for col in cols:\n",
    "    display_category_percentage(X_train, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label BrkCmn is present in 1% of the observations. Since it is the only category under-represented, creating a new category called 'Rare' to group this label does not make much sense, as the new label Rare will be in essence the same as BrkCmn, and still under-represented.\n",
    "\n",
    "Thus, we may choose to replace the rare label by the most frequent category, in this case, 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare value imputation\n",
    "- The identification of rare labels should be done considering only the presence of rare labels in the training set, and then propagated to the test set. \n",
    "- This means, rare labels should be identified in the training set. And then, when those are present in the test set as well, they should be replaced, regardless of whether in the test set they are rare or not.\n",
    "- In addition, there may be labels in the test set that were not present in the train set. They should be considered rare and preprocessed using the method that was selected to replace rare labels in the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rare_imputation(train, test, variable):\n",
    "    \n",
    "    # find frequest category in train\n",
    "    freq_cat = train[variable].value_counts().index[0]\n",
    "    \n",
    "    # find rare categories in train\n",
    "    S = train[variable].value_counts(normalize=True) \n",
    "    rare_cat = S[S < 0.05].index.values\n",
    "    \n",
    "    # create new categorical variables with rare values imputed\n",
    "    \n",
    "    # Approach 1. by most frequent category\n",
    "    freq_dict = {k:freq_cat for k in rare_cat}\n",
    "    \n",
    "    train[variable + '_freq'] = train[variable].apply(lambda x : freq_dict[x] if x in freq_dict.keys() else x)\n",
    "    test[variable + '_freq'] = test[variable].apply(lambda x : freq_dict[x] if x in freq_dict.keys() else x)\n",
    "    \n",
    "    # Approach 2. by adding a new category label as Rare\n",
    "    train[variable + '_rare'] = np.where(train[variable].isin(rare_cat), 'Rare', train[variable])\n",
    "    test[variable + '_rare'] = np.where(test[variable].isin(rare_cat), 'Rare', test[variable])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imputation\n",
    "rare_imputation(X_train, X_test, 'MasVnrType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None       60.1%\n",
      "BrkFace    29.5%\n",
      "Stone       9.5%\n",
      "BrkCmn      1.0%\n",
      "Name: MasVnrType, dtype: object\n",
      "\n",
      "None       61.1%\n",
      "BrkFace    29.5%\n",
      "Stone       9.5%\n",
      "Name: MasVnrType_freq, dtype: object\n",
      "\n",
      "None       60.1%\n",
      "BrkFace    29.5%\n",
      "Stone       9.5%\n",
      "Rare        1.0%\n",
      "Name: MasVnrType_rare, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After rare value imputation \n",
    "\n",
    "for col in X_train.columns[X_train.columns.str.startswith('MasVnrType')]:\n",
    "    display_category_percentage(X_train, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA    62.6%\n",
      "Gd    33.3%\n",
      "Ex     2.9%\n",
      "Fa     1.2%\n",
      "Name: ExterQual, dtype: object\n",
      "\n",
      "TA    66.7%\n",
      "Gd    33.3%\n",
      "Name: ExterQual_freq, dtype: object\n",
      "\n",
      "TA      62.6%\n",
      "Gd      33.3%\n",
      "Rare     4.1%\n",
      "Name: ExterQual_rare, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  imputation\n",
    "rare_imputation(X_train, X_test, 'ExterQual')\n",
    "\n",
    "cols=['ExterQual', 'ExterQual_freq', 'ExterQual_rare']\n",
    "for col in cols:\n",
    "    display_category_percentage(X_train, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore examples in which variables have several categories, say more than 10\n",
    "\n",
    "def get_highcardinality_columns(dataframe):\n",
    "    return [col for col in dataframe.columns if (dataframe[col].dtype == 'O') and (dataframe[col].nunique() > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare imputation for LotFrontage done\n",
      "Rare imputation for Neighborhood done\n",
      "Rare imputation for Exterior1st done\n",
      "Rare imputation for Exterior2nd done\n",
      "Rare imputation for MasVnrArea done\n",
      "Rare imputation for GarageYrBlt done\n"
     ]
    }
   ],
   "source": [
    "# rare imputation for high cardinality columns\n",
    "for col in get_highcardinality_columns(X_train):\n",
    "    rare_imputation(X_train, X_test, col)\n",
    "    print(f'Rare imputation for {col} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None     18.5%\n",
      "60.0      9.2%\n",
      "80.0      5.5%\n",
      "50.0      4.0%\n",
      "75.0      3.5%\n",
      "         ...  \n",
      "112.0     0.1%\n",
      "109.0     0.1%\n",
      "174.0     0.1%\n",
      "103.0     0.1%\n",
      "182.0     0.1%\n",
      "Name: LotFrontage, Length: 102, dtype: object\n",
      "\n",
      "None    85.3%\n",
      "60.0     9.2%\n",
      "80.0     5.5%\n",
      "Name: LotFrontage_freq, dtype: object\n",
      "\n",
      "Rare    66.8%\n",
      "None    18.5%\n",
      "60.0     9.2%\n",
      "80.0     5.5%\n",
      "Name: LotFrontage_rare, dtype: object\n",
      "\n",
      "NAmes      14.8%\n",
      "CollgCr    10.3%\n",
      "OldTown     7.1%\n",
      "Edwards     6.9%\n",
      "Sawyer      6.0%\n",
      "Somerst     5.5%\n",
      "Gilbert     5.4%\n",
      "NWAmes      5.0%\n",
      "NridgHt     5.0%\n",
      "SawyerW     4.4%\n",
      "BrkSide     4.0%\n",
      "Mitchel     3.5%\n",
      "Crawfor     3.4%\n",
      "NoRidge     2.9%\n",
      "Timber      2.9%\n",
      "ClearCr     2.3%\n",
      "IDOTRR      2.3%\n",
      "SWISU       1.8%\n",
      "StoneBr     1.6%\n",
      "Blmngtn     1.2%\n",
      "MeadowV     1.2%\n",
      "BrDale      1.0%\n",
      "NPkVill     0.7%\n",
      "Veenker     0.6%\n",
      "Blueste     0.2%\n",
      "Name: Neighborhood, dtype: object\n",
      "\n",
      "NAmes      58.8%\n",
      "CollgCr    10.3%\n",
      "OldTown     7.1%\n",
      "Edwards     6.9%\n",
      "Sawyer      6.0%\n",
      "Somerst     5.5%\n",
      "Gilbert     5.4%\n",
      "Name: Neighborhood_freq, dtype: object\n",
      "\n",
      "Rare       44.0%\n",
      "NAmes      14.8%\n",
      "CollgCr    10.3%\n",
      "OldTown     7.1%\n",
      "Edwards     6.9%\n",
      "Sawyer      6.0%\n",
      "Somerst     5.5%\n",
      "Gilbert     5.4%\n",
      "Name: Neighborhood_rare, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "highcardinality_cols=['LotFrontage', 'Neighborhood']\n",
    "\n",
    "for hcol in highcardinality_cols:\n",
    "    for col in X_train.columns[X_train.columns.str.startswith(hcol)]:\n",
    "        display_category_percentage(X_train, col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_6",
   "language": "python",
   "name": "test_env_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
